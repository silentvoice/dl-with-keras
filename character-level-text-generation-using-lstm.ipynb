{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "character-level-text-generation-using-lstm.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/silentvoice/dl-with-keras/blob/master/character-level-text-generation-using-lstm.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "F2XPKWVopuoS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Check Tensorflow Version"
      ]
    },
    {
      "metadata": {
        "id": "ayZ2tBHxqHvq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aVn4pBt4qKPC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c438703c-14f0-479e-f959-89a0ec2530fa"
      },
      "cell_type": "code",
      "source": [
        "tf.test.is_gpu_available()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "HSo8WdUpqTVd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff6d676f-aeef-4a7f-fd97-a73ad3202f65"
      },
      "cell_type": "code",
      "source": [
        "tf.keras.__version__"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.6-tf'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "V4j8KSn8qZe1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "237615c9-fb28-4176-cb12-cbd780160c0a"
      },
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.9.0-rc2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "5ma-lxYMrBLD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "id": "clrwVKTlq0JB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import layers, models\n",
        "from tensorflow.python.keras import optimizers\n",
        "import numpy as np\n",
        "import random, sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y0vwgKDVq9Mx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "metadata": {
        "id": "j_lnbeHlrK2l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = keras.utils.get_file('nietzsche.txt',origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "txt = open(path).read().lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6tpCN2KrdDI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd975cde-fc20-4606-ebf2-148fe3ec9511"
      },
      "cell_type": "code",
      "source": [
        "len(txt)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "600893"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "pehDIB9qry-v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "maxlen = 60\n",
        "step = 3\n",
        "sentences = []\n",
        "nxt_chars = []\n",
        "\n",
        "for idx in range(0, len(txt) - maxlen, step):\n",
        "  sentences.append(txt[idx: idx + maxlen])\n",
        "  nxt_chars.append(txt[idx + maxlen])                        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1tMZ3cyisi6S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e032d905-51d2-45a3-c8af-ee7eec17b5a3"
      },
      "cell_type": "code",
      "source": [
        "len(sentences)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200278"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "_f8AeRmtskse",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(txt)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T9_aZdbIs2Rj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "char_indices = dict((c, chars.index(c)) for c in chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vI0oGSFCtHxb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## One hot encode characters"
      ]
    },
    {
      "metadata": {
        "id": "bsCnM2y3tSND",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "024B46pAtw_y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for s_idx, s in enumerate(sentences):\n",
        "  for c_idx, c in enumerate(s):\n",
        "    x[s_idx, c_idx, char_indices[c]] = 1\n",
        "  y[s_idx, char_indices[nxt_chars[s_idx]]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QRRm-BKPuXDC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build Model"
      ]
    },
    {
      "metadata": {
        "id": "f-_EF7flukjv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tbvLTUShu4_M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=0.01))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5aqJdQEHvKs_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "49f99af3-e717-439d-cdfd-23456e6d1501"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 128)               95232     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 57)                7353      \n",
            "=================================================================\n",
            "Total params: 102,585\n",
            "Trainable params: 102,585\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m89TVdtxvPAN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ]
    },
    {
      "metadata": {
        "id": "2CN_8fGNyByK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2074
        },
        "outputId": "abd5e991-c6d9-4045-a79b-2b834e40bd22"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size=128, epochs=60)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "200278/200278 [==============================] - 276s 1ms/step - loss: 2.0012\n",
            "Epoch 2/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 275s 1ms/step - loss: 1.6405\n",
            "Epoch 3/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 276s 1ms/step - loss: 1.5488\n",
            "Epoch 4/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 274s 1ms/step - loss: 1.5001\n",
            "Epoch 5/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 274s 1ms/step - loss: 1.4689\n",
            "Epoch 6/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 274s 1ms/step - loss: 1.4492\n",
            "Epoch 7/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 273s 1ms/step - loss: 1.4316\n",
            "Epoch 8/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 275s 1ms/step - loss: 1.4167\n",
            "Epoch 9/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 273s 1ms/step - loss: 1.4059\n",
            "Epoch 10/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 275s 1ms/step - loss: 1.3957\n",
            "Epoch 11/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 274s 1ms/step - loss: 1.3881\n",
            "Epoch 12/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 275s 1ms/step - loss: 1.3796\n",
            "Epoch 13/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 275s 1ms/step - loss: 1.3749\n",
            "Epoch 14/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 274s 1ms/step - loss: 1.3674\n",
            "Epoch 15/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 275s 1ms/step - loss: 1.3596\n",
            "Epoch 16/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 275s 1ms/step - loss: 1.3581\n",
            "Epoch 17/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 276s 1ms/step - loss: 1.3521\n",
            "Epoch 18/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 276s 1ms/step - loss: 1.3472\n",
            "Epoch 19/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 277s 1ms/step - loss: 1.3412\n",
            "Epoch 20/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 276s 1ms/step - loss: 1.3407\n",
            "Epoch 21/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 276s 1ms/step - loss: 1.3667\n",
            "Epoch 22/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 276s 1ms/step - loss: 1.3514\n",
            "Epoch 23/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 277s 1ms/step - loss: 1.3509\n",
            "Epoch 24/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 276s 1ms/step - loss: 1.3410\n",
            "Epoch 25/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 276s 1ms/step - loss: 1.3516\n",
            "Epoch 26/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 277s 1ms/step - loss: 1.3407\n",
            "Epoch 27/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 277s 1ms/step - loss: 1.3352\n",
            "Epoch 28/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 276s 1ms/step - loss: 1.3219\n",
            "Epoch 29/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 277s 1ms/step - loss: 1.3323\n",
            "Epoch 30/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 275s 1ms/step - loss: 1.3271\n",
            "Epoch 31/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 277s 1ms/step - loss: 1.4048\n",
            "Epoch 32/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 275s 1ms/step - loss: 1.3698\n",
            "Epoch 33/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 275s 1ms/step - loss: 1.3412\n",
            "Epoch 34/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 276s 1ms/step - loss: 1.3359\n",
            "Epoch 35/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 274s 1ms/step - loss: 1.3904\n",
            "Epoch 36/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 277s 1ms/step - loss: 1.3989\n",
            "Epoch 37/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 278s 1ms/step - loss: 1.3870\n",
            "Epoch 38/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 277s 1ms/step - loss: 1.3700\n",
            "Epoch 39/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 275s 1ms/step - loss: 1.3526\n",
            "Epoch 40/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 274s 1ms/step - loss: 1.3500\n",
            "Epoch 41/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 273s 1ms/step - loss: 1.3428\n",
            "Epoch 42/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 274s 1ms/step - loss: 1.3271\n",
            "Epoch 43/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 272s 1ms/step - loss: 1.3223\n",
            "Epoch 44/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 271s 1ms/step - loss: 1.3247\n",
            "Epoch 45/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 272s 1ms/step - loss: 1.3222\n",
            "Epoch 46/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 276s 1ms/step - loss: 1.3228\n",
            "Epoch 47/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 275s 1ms/step - loss: 1.3248\n",
            "Epoch 48/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 276s 1ms/step - loss: 1.3249\n",
            "Epoch 49/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 277s 1ms/step - loss: 1.3177\n",
            "Epoch 50/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 276s 1ms/step - loss: 1.3239\n",
            "Epoch 51/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 277s 1ms/step - loss: 1.3493\n",
            "Epoch 52/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 276s 1ms/step - loss: 1.6186\n",
            "Epoch 53/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 276s 1ms/step - loss: 1.3671\n",
            "Epoch 54/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 276s 1ms/step - loss: 1.3229\n",
            "Epoch 55/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 275s 1ms/step - loss: 1.4337\n",
            "Epoch 56/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 276s 1ms/step - loss: 1.3693\n",
            "Epoch 57/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 273s 1ms/step - loss: 1.3242\n",
            "Epoch 58/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 274s 1ms/step - loss: 1.3497\n",
            "Epoch 59/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 277s 1ms/step - loss: 1.4038\n",
            "Epoch 60/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200278/200278 [==============================] - 276s 1ms/step - loss: 1.3507\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3ce98e9a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "mNPMup_51E6m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate Text From Model"
      ]
    },
    {
      "metadata": {
        "id": "9WhLT9sB1LFG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample(preds, t=1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds) / t\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probs = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J-zNYs7j1L5l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "strt_idx = random.randint(0, len(txt) - maxlen - 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aGVUexKX1jUM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "20702c7b-f11f-4e76-9d4c-8e5ab3b0b430"
      },
      "cell_type": "code",
      "source": [
        "for t in [0.2, 0.5, 1.0, 1.2]:\n",
        "  seed_txt = txt[strt_idx: strt_idx + maxlen] \n",
        "  gen_txt = seed_txt\n",
        "  for _ in range(400):\n",
        "    sampled = np.zeros((1, maxlen, len(chars)))\n",
        "    # one hot encode seed characters\n",
        "    for c_idx, c in enumerate(seed_txt):\n",
        "      sampled[0, c_idx, char_indices[c]] = 1\n",
        "      \n",
        "    preds = model.predict(sampled)[0]\n",
        "    nxt_idx = sample(preds, t)\n",
        "    nxt_char = chars[nxt_idx]\n",
        "    gen_txt +=nxt_char\n",
        "    seed_txt += nxt_char\n",
        "    seed_txt = seed_txt[1:]\n",
        "  print(gen_txt)  "
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " being badly endowed by nature,\n",
            "and finally, it is an opportuneation of the spirit the greater of the sense of the spirit of the present the present the present the fact the present the moral and say the sense of the sense of the strongt and development of \"man's science of the sense of the best and stronger and the intellectual interpretation of the soul, the problem of the fact the truth and conception of the moral and comparation of the conduct of the s\n",
            " being badly endowed by nature,\n",
            "and finally, it is an opportune fact the conscience and rational increased the present and morality of the world, but really the for the entire mankind, be the spirit the truth,\" in the way, the deception of the profound and have \"the far as the german intellect to the entingly mediocve the science,\" and called the belief, and strive and defenilation of the man is the world of values,\" and in the sense and case of the presen\n",
            " being badly endowed by nature,\n",
            "and finally, it is an opportuneable rif the last and robly and spirit: verytelled inous purst and lo uncleakanceronism\n",
            "and\n",
            "concensquians,\" nucy irrory; what it is not dangerou,\n",
            "moral dosmarrs a\n",
            "master\n",
            "as this\n",
            "sake need, the greatest laires, and man\"\n",
            "fit,\n",
            "problem,\" moreover, i sucag'nge onca, far to uticvant affends the best with new else self-essence\n",
            "of the captive, allowed christian thinking, makes in cognitives grow consta\n",
            " being badly endowed by nature,\n",
            "and finally, it is an opportunes and mankind to did naught.\n",
            "\n",
            "1\n",
            "u] by the leaster would not he is call thiust (a conception of schoppre., aäë ofs overs, and the feeling of mystialt remorce.\n",
            "\n",
            "\n",
            "13äerwearis that is through i now be double of greeow calvatic time\n",
            "of preasion for science for honjus, \"gionom--they are\n",
            "its ratting,\" in justice: fear\n",
            "once-leamrion,\n",
            "que,hon. there is\n",
            "god could arething,\n",
            "alonety,--he\n",
            "much\n",
            "act\n",
            "glorace t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wMUs5S5e40Sp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c3087b1c-72c6-4ed0-a481-e1978828d9ca"
      },
      "cell_type": "code",
      "source": [
        "t=0.5\n",
        "strt_idx = random.randint(0, len(txt) - maxlen - 1)\n",
        "seed_txt = txt[strt_idx: strt_idx + maxlen] \n",
        "gen_txt = seed_txt\n",
        "for _ in range(400):\n",
        "  sampled = np.zeros((1, maxlen, len(chars)))\n",
        "# one hot encode seed characters\n",
        "  for c_idx, c in enumerate(seed_txt):\n",
        "    sampled[0, c_idx, char_indices[c]] = 1\n",
        "  preds = model.predict(sampled)[0]\n",
        "  nxt_idx = sample(preds, t)\n",
        "  nxt_char = chars[nxt_idx]\n",
        "  gen_txt +=nxt_char\n",
        "  seed_txt += nxt_char\n",
        "  seed_txt = seed_txt[1:]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "X0dDBblFrzKi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d76244fd-f2d1-45ce-d67b-d85e0c65ee2d"
      },
      "cell_type": "code",
      "source": [
        "gen_txt"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'manly, conquering, and imperious--all instincts which are nature in the \"struggle and do not in order to him the freedom and problem the fact in german call the greater come and \"good very fings the strength to the german things in all the end of the moral outsima than the more such a regard that it is be promise as a powerfnh, he less down are the science of simple and the fact in the mind the tragedy, with the enting from the promises of the future, and '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "HKI8h-qqr0X4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}